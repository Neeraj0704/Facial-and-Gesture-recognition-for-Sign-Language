# Install necessary libraries
!pip install tensorflow keras torch torchvision numpy pandas opencv-python scikit-learn matplotlib

# Import libraries
import numpy as np
import pandas as pd
import cv2
import tensorflow as tf
import torch
import torchvision.transforms as transforms
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from tensorflow.keras.optimizers import Adam,SGD
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0,EfficientNetB3  # EfficientNetB0 or EfficientNetB3
from tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define data directories
train_dir = r"C:\Users\neera\OneDrive\Desktop\Facial_Dataset\train"
val_dir = r"C:\Users\neera\OneDrive\Desktop\Facial_Dataset\test"


from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Create an ImageDataGenerator for data augmentation and normalization
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=True,  # Add vertical flipping
    fill_mode='nearest',
    brightness_range=[0.8, 1.2],
    contrast_range=[0.8, 1.2],  # Add contrast adjustment
    channel_shift_range=50.0    # Add channel shifting
)

val_datagen = ImageDataGenerator(rescale=1./255)

# Create the generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(48, 48),
    batch_size=32,
    class_mode='categorical',
    color_mode='rgb'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(48, 48),
    batch_size=32,
    class_mode='categorical',
    color_mode='rgb'
)

import tensorflow as tf

def preprocess_image(image, label):
    image = tf.image.resize(image, [48, 48])
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    image = tf.image.random_brightness(image, max_delta=0.2)
    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)
    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)
    image = image / 255.0
    return image, label

def load_and_preprocess_image(filename, label):
    image = tf.io.read_file(filename)
    image = tf.image.decode_jpeg(image, channels=3)
    return preprocess_image(image, label)

# Create Dataset
def get_dataset(directory, batch_size):
    dataset = tf.data.Dataset.list_files(directory + '/*/*.jpg')
    dataset = dataset.map(lambda x: (x, tf.strings.to_number(tf.strings.regex_full_match(x, directory + '/([^/]+)'))))
    dataset = dataset.map(load_and_preprocess_image)
    dataset = dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)
    return dataset

train_ds = get_dataset(train_dir, batch_size=32)
val_ds = get_dataset(val_dir, batch_size=32)

def preprocess_image(image, label):
    image = tf.image.resize(image, [48, 48])  # Resize images to target size
    image = image / 255.0  # Normalize pixel values
    return image, label

# Apply preprocessing in dataset pipeline
def load_and_preprocess_image(filename, label):
    image = tf.io.read_file(filename)
    image = tf.image.decode_jpeg(image, channels=3)
    return preprocess_image(image, label)

# Number of classes in your dataset
num_classes = len(train_generator.class_indices)


# Load EfficientNetB0 without top layers and specify input shape as (48, 48, 3) for RGB
base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(48, 48, 3))
# If you want to use EfficientNetB3, replace EfficientNetB0 with EfficientNetB3 in the above line

# Add custom layers on top
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(num_classes, activation='softmax')(x)  # Output layer with num_classes units

model = Model(inputs=base_model.input, outputs=x)

# Freeze base model layers
for layer in base_model.layers:
    layer.trainable = False

# Compile model
optimizer = Adam(learning_rate=0.0001)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

from sklearn.utils import class_weight
import numpy as np

# Calculate class weights
class_weights = class_weight.compute_class_weight(
    'balanced',
    classes=np.unique(train_generator.classes),
    y=train_generator.classes
)
class_weights = dict(enumerate(class_weights))

# In your model's fit method
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=3,  # Change epochs as needed
    validation_data=val_generator,
    validation_steps=val_generator.samples // val_generator.batch_size,
    class_weight=class_weights
)


scores = model.evaluate(val_generator, steps=val_generator.samples // val_generator.batch_size)

# Print the evaluation results
print(f'Validation Loss: {scores[0]}')
print(f'Validation Accuracy: {scores[1]}')

model.save('facial_model.keras')
